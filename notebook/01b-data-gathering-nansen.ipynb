{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Timestamps\n",
    "\n",
    "**[Johnnatan Messias](https://johnnatan-messias.github.io/), August 2024**\n",
    "\n",
    "Understanding when each vote was cast is essential for analyzing the dynamics of governance in decentralized autonomous organizations (DAOs). However, event logs on-chain do not include timestamps by default. To obtain this information, we need to retrieve the block data associated with each transaction related to governance events.\n",
    "\n",
    "Since querying an Ethereum Archive Node can be time-consuming, we use the [Nansen Query API](https://query.nansen.ai/) to fetch the block timestamps more efficiently.\n",
    "\n",
    "Alternative data sources include platforms like [Dune](https://dune.com/) or Google BigQuery. If these services are unavailable, we've included a code snippet at the bottom of this Jupyter notebook that fetches block timestamps using an Ethereum Archive Node provided by Paradigm. You can also modify the code to use any other Ethereum node endpoints, including a node you operate yourself.\n",
    "\n",
    "The notebook includes all the code used to fetch and store the block timestamps. The results are saved in a compressed CSV file:  \n",
    "`./data/blocks/block_timestamp_9600000_20563001.csv.gz`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common variables and imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.path.realpath(os.path.join(\n",
    "    os.getcwd(), \"..\", \"data\", \"blocks\"))\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using [Nansen Query API](https://query.nansen.ai/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "%load_ext google.cloud.bigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar_type = 'tqdm_notebook'\n",
    "project_id = 'Add your project id here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_number_start, block_number_end = 9_600_000, 20_563_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "    number, timestamp\n",
    "FROM\n",
    "    `nansen-query.raw_ethereum.blocks`\n",
    "WHERE\n",
    "    number >= {block_number_start} AND number <= {block_number_end}\n",
    "ORDER BY\n",
    "    number DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = sql.format(block_number_start=block_number_start,\n",
    "                   block_number_end=block_number_end)\n",
    "\n",
    "df = pandas_gbq.read_gbq(\n",
    "    query, project_id=project_id, progress_bar_type=progress_bar_type)\n",
    "\n",
    "filename = \"block_timestamp_{}_{}.csv.gz\".format(\n",
    "    block_number_start, block_number_end)\n",
    "\n",
    "filedir = os.path.realpath(os.path.join(data_dir, filename))\n",
    "\n",
    "df.to_csv(filedir, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ethereum Archive Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web3 import Web3\n",
    "import requests as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_number_start_test, block_number_end_test = 20_550_000, 20_563_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "code_dir = os.path.realpath(os.path.join(os.getcwd(), \"..\", \"src\"))\n",
    "\n",
    "sys.path.append(code_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ethereum import get_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code connects to Paradigm Reth archive node (see https://x.com/gakonst/status/1702389827390546071)\n",
    "eth_node = 'http://69.67.151.138:8545'\n",
    "\n",
    "adapter = re.adapters.HTTPAdapter(pool_connections=20, pool_maxsize=20)\n",
    "session = re.Session()\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "w3 = Web3(Web3.HTTPProvider(eth_node, session=session,\n",
    "          request_kwargs={'timeout': 60}))\n",
    "\n",
    "print(\"Is connected to Ethereum node: \", w3.is_connected())\n",
    "print(\"The most recent block is: \", w3.eth.block_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering blocks belonging to the range 20_550_000 and 20_563_001 for exemplification.\n",
    "blocks = get_blocks(w3, block_numbers=range(\n",
    "    block_number_start_test, block_number_end_test))\n",
    "blocks_df = pd.DataFrame(blocks)\n",
    "blocks_df = blocks_df[[\"number\", \"timestamp\"]]\n",
    "blocks_df.sort_values(by=\"number\", inplace=True)\n",
    "blocks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_block_timestamp_{}_{}.csv.gz\".format(\n",
    "    block_number_start_test, block_number_end_test)\n",
    "\n",
    "filedir = os.path.realpath(os.path.join(data_dir, filename))\n",
    "blocks_df.to_csv(filedir, index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
